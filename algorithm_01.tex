\chapter{Garment Segmentation}
\label{garment_segmentation}
This chapter is devoted to the first part of our algorithm, extracting the garment data from the sensor data. Data is obtained as a point cloud, and then converted to a depth image. Then, garment segmentation is perfomed.

\section{Data adquisition}
\label{data_adquisition}

The starting point of our algorithm is the data adquisition process. Data is obtained as a point cloud from a ASUS Xtion Live sensor. Then, data is converted to a depth map image for its later analysis. 

This conversion is done by simply using the z component of each point as the depth value for each pixel of the depth image. This depth image could also be recovered from the point cloud using the instrinsic and extrinsic paramters of the sensor. But, as the sensor is placed on top of the garment, perpendicular to the surface on which the clothing article rests, both methods yield almost very similar results.

\begin{figure}[thpb]
    \centering
    \includegraphics[width=0.7
    \textwidth]{figures/placeholder2.png}
    \caption{\comment{Here I should put a nice figure of the point cloud and the depth image}}
    \label{fig:point_cloud_and_depth_image}
\end{figure}

The RGB values are also recorded for each depth image, obtaining an RBG-D image.

\section{Garment segmentation}
\label{garment_segmentation_mask}

The RGB-D image obtained in the previous step contains both the clothing article and the table on which it rests. Therefore, after retrieving the data, a segmentation process is required to classify whether a pixel represents the garment or the table.

For this purpose, many methods could have been chosen, based on both color and depth information. But, as the main focus of our work is unfolding clothes, a simple color-based method was selected. 

We work under the assumption that the garment has been placed over a flat clear surface, as opposed to the garment which is much more colorful (saturated). First, the RGB image was converted to the HSV space. Working in the HSV space gives us direct information about our magnitudes of interest: saturation and intensity. As preprocessing, to reduce the effect of the noise on the segmentation process, a convolution with a 5x5 Gaussian kernel with $\sigma=1.1$ is computed on the saturation (S) and value (V) channels of the HSV image.

A thresholding operation is then applied to the filtered image, using Otsu's algorithm \comment{(ref, maybe?)} to obtain the optimal threshold values. Pixels with low amount of saturation, and a high values are classified as being part of the table, as opposed to dark or saturated pixels.

Finally, some morphological transformations are applied to the resulting mask to reduce noise due to false positives/negatives. A 5x5 squared kernel is used in several closing operations, followed by a similar number of opening operations.


\begin{figure}[thpb]
    \centering
    \includegraphics[width=0.48
    \textwidth]{figures/placeholder.png}
    \caption{\comment{Again, I should put here a picture of the resulting mask}}
    \label{fig:segmentation_mask}
\end{figure}

\section{Depth image preprocessing}
\label{depth_image_preprocessing}

Once the garment mask has been calculated, it is applied to the depth image of the garment to discard the information related to the table. The garment depth data is then normalized to prepare it for posterior analysis steps.