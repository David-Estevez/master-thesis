\chapter{\MyTitle}
\label{architecture}

This chapter presents an overview of a garment-agnostic algorithm to unfold clothes using depth sensor data, that will be extended in later chapters. Our work differs with most of the state of the art in the fact that garment models are not used. Our approach uses depth information captured with a depth sensor to detect folds in a garment. The most suitable grasping position, unfolding direction, and release point are computed.

The algorithm can be divided into three main stages (Fig \ref{fig:pipeline_block_diagram}). First, the  background is extracted from the image and the contour of the garment is approximated. Then, a depth map clustering process is performed to estimate overlapping regions. Finally, the information obtained in the previous process is used to determine if there are any folds present and how to interact with the garment to unfold it. The algorithm has been open sourced and is available online\footnote{\url{https://github.com/roboticslab-uc3m/textiles}}.

\begin{figure}[thpb]
    \centering
    \includegraphics[width=0.8
    \textwidth]{figures/placeholder2.png}
    \caption{\comment{A nice figure of the whole pipeline block diagram}}
    \label{fig:pipeline_block_diagram}
\end{figure}

\section{Garment Segmentation}
Prior to any cloth analysis, a background extraction has to be performed in order to remove all information not related to the garment.


\begin{figure}[thpb]
    \centering
    \includegraphics[width=0.8
    \textwidth]{figures/placeholder2.png}
    \caption{\comment{A nice figure of a generic Garment Segmentation}}
    \label{fig:generic_garment_segmentation}
\end{figure}

Based on the assumption that the clothing article is placed on top of a flat white surface, the garment can be segmented by color. This can be performed by threshold operations on the red, green and blue channels of the RGB space, or on the hue, saturation and value channels of the HSV space. Other color spaces could also be used. GrabCut \reftodo, that uses gaussian mixture models (GMMs) and iterative energy minimization, is another available method to separate the background and foreground based on color.

Another potential approach is to remove the horizontal plane of the table using depth information. This approach can be further improved by combining the results obtained by the depth-based segmentation with a color segmentation, in case the garment color and the background are dissimilar enough.

Once the background is extracted, the contour of the garment has to be determined. Several methods exist for this purpose. The Topological Analysis by Border Following algorithm developed by Suzuki and Abe \reftodo \comment{(suzuki85)} is a widely used algorithm for connected-component labeling and countour finding. A Marching Squares \reftodo algorithm can be also applied to find constant valued contours in an image.

After the contour is extracted, it is then approximated to a polygon, e.g. using the Ramer-Douglas-Peucker algorithm \reftodo. Alternative algorithms exist, such as the Teh-Chin algorithm to find Dominant Points \reftodo \comment{(Teh-Chin89)}. Each of the segments obtained is a candidate for being a fold axis. The midpoints of those fold axis candidates are calculated to be used in the following steps.

The segmentation process used in this thesis is further explained in chapter \ref{garment_segmentation}.

\section{Garment Depth Map Clustering}
When the garment has been identified, garment regions with similar height points must be clustered and labeled. \comment{For this task we apply the watershed algorithm\footnote{\url{http://scikit-image.org/docs/dev/auto_examples/plot_watershed.html}} \reftodo to the depth image. }

\begin{figure}[thpb]
    \centering
    \includegraphics[width=0.8
    \textwidth]{figures/placeholder2.png}
    \caption{\comment{A nice figure of a generic Superpixels}}
    \label{fig:generic_superpixels}
\end{figure}

\comment{The image returned by the watershed algorithm is labeled by regions of similar heights, Fig. \ref{fig:color_garment}. By using only depth information, as opposed to using RGB images, makes our algorithm independent of the colors and patterns present in the garments.}

The garment depth map clustering process used in this thesis is developed in more detail in chapter \ref{garment_clustering}.

\section{Garment Pick and Place Points}
On the labeled watershed image, we calculate the average height value of each region, and assign this average value to all points in the region. The region with the highest average height is selected for further analysis. 

The next step, after having labeled the similar-height regions and found the highest region, is to find the unfold direction. The assumption made here is that the fold has at least one contour edge which is also a border of the garment. 

A set of candidate paths is generated, all of them starting at the centroid of the highest region, and ending in each contour segment midpoint. Each candidate path is analyzed and assigned a value calculated by penalizing the changes in the height of the path.

Up to here, we have detected the most promising direction to unfold. Finally, we need to define is the exact point where the robot has to pick the garment, and the place point. 

For this, we extend the previously selected direction line. The garment pick point is chosen at the intersection of the direction line with the inner region border. To find this point, we compute the intersection between the line and the region contour, and select the point furthest to the garment border.

On the other side, the place point is selected by computing the symmetric point of the pick point with respect to the garment edge intersection point. The unfold directions, departing from the pick point and arriving at the place point of a set of clothes, is shown in Fig. \ref{fig:directions}.
